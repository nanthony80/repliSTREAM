---
title: "lulu_barque"
author: "Nicole Anthony"
date: "`r Sys.Date()`"
output: html_document
---

# Introduction
This analysis uses publicly available data from Ballini et al. (2024). eDNA metabarcoding sample sequences were initially processed using Barque (v1.8.5, https:// github. com/ enormandeau/ barque), an eDNA metabarcoding analysis pipeline that denoises and then annotates amplicon sequence variants (ASVs) or operational taxonomic units (OTUs) using high-quality reference databases. A curated reference database was created using Creating Reference databases for Amplicon-Based Sequencing (CRABS) as per Ballini et al. (2024) with some modifications. See Barque settings and CRABS modifications in repliSTREAM README.md.

## Post-Clustering curation of OTU data using LULU
In this analysis, we used the LULU R package (v0.1.0, https://github.com/tobiasgf/lulu) to curate an OTU table by identifying and merging spurious OTUs that arise due to sequencing errors or minor variants of more abundant OTUs. LULU improves biodiversity metrics by reducing overestimation caused by such errors. This post-clustering curation approach is essential for producing more accurate and biologically meaningful results.

The LULU algorithm operates by analyzing sequence similarity and co-occurrence patterns among OTUs across samples. OTUs with high sequence similarity to more abundant OTUs and consistent co-occurrence patterns are flagged as likely errors and merged accordingly.

### Set-up for LULU
Copy the following files to a new directory called 'lulu_barque'.

- `marker_species_table.csv` files in the 12_results directory from the second barque run (`tele02_species_table.csv` and `vert01_species_table.csv`)
- `marker.otus.database.fasta.gz` files in the 13_otu_database directory from the first Barque (`tele02.otus.database.fasta.gz` and `vert01.otus.database.fasta.gz`)

### Output for microDecon
After running LULU, the following curated OTU tables generated by the LULU algorithm were used as input for decontamination using microDecon (v1.0.2) and the script `08_microDecon_barque.Rmd`.

- `tele02_curated_otu_table.csv`
- `vert01_curated_otu_table.csv`

These tables include negative control (blank) samples, which were used by microDecon to identify and remove contamination based on default settings.

## References

Ballini, L., Staffoni, G., Nespoli, D., et al. (2025). Environmental DNA metabarcoding as an efficient tool to monitor freshwater systems in northwestern Italy. Hydrobiologia, 852, 791–803. https://doi.org/10.1007/s10750-024-05723-y

Frøslev, T. G., Kjøller, R., Bruun, H. H., et al. (2017). Algorithm for post-clustering curation of DNA amplicon data yields reliable biodiversity estimates. Nature Communications, 8, 1188. https://doi.org/10.1038/s41467-017-01312-x

Jeunen, G. J., Dowle, E., Edgecombe, J., von Ammon, U., Gemmell, N. J., & Cross, H. (2023). crabs: A software program to generate curated reference databases for metabarcoding sequencing data. Molecular Ecology Resources, 23(3), 725–738. https://doi.org/10.1111/1755-0998.13741

Mathon, L., Valentini, A., Guérin, P. E., Normandeau, E., Noel, C., Lionnet, C., Boulanger, E., Thuiller, W., Bernatchez, L., Mouillot, D., Dejean, T., & Manel, S. (2021). Benchmarking bioinformatic tools for fast and accurate eDNA metabarcoding species identification. Molecular Ecology Resources, 21(7), 2565–2579. https://doi.org/10.1111/1755-0998.13430



# Install package and load libraries
```{r}
# library(devtools)
# install_github("tobiasgf/lulu")
library(lulu)
library(tidyverse)
library(dplyr)
```

# Prepare OTU Tables

## Tele02 OTU Table
```{r}
# load the marker species table from second Barque run and inspect
tele02 <- read_csv("tele02_species_table.csv")
head(tele02)
colnames(tele02)

# convert tele02 species table to LULU format with samples as cols and OTUs with unique ID's as rows
# select the TaxonName column and all sample columns that start with "SRR"
tele02_otu_table <- tele02 %>%
  select(TaxonName, starts_with("SRR")) # select OTU IDs + sample count columns
head(tele02_otu_table)

# rename TaxonName to OTUid (LULU expects OTU IDs in the first column) and inspect
tele02_otu_table <- tele02_otu_table %>%
  rename(OTUid = TaxonName)
head(tele02_otu_table)
dim(tele02_otu_table)

# coerce all sample columns (except OTU IDs) to numeric
tele02_otu_table <- tele02_otu_table %>%
  mutate(across(starts_with("SRR"), as.numeric)) # ensure sample counts are numeric

# move OTUid to row names (LULU expects OTU IDs as row names, not as a column)
tele02_otu_table <- tele02_otu_table %>%
  column_to_rownames(var = "OTUid")

# check if OTU IDs are unique
n_unique <- length(rownames(tele02_otu_table)) == length(unique(rownames(tele02_otu_table)))

if (n_unique) {
  print("All OTU IDs are unique!")
} else {
  print("Warning: There are duplicate OTU IDs!")
}

# check for duplicate OTUs
tele02_duplicate_otus <- tele02_otu_table %>%
  as.data.frame() %>%
  tibble::rownames_to_column(var = "OTUid") %>%  # Convert row names back to a column
  count(OTUid) %>%
  filter(n > 1)

# print duplicates
if (nrow(tele02_duplicate_otus) > 0) {
  print("Duplicates found:")
  print(tele02_duplicate_otus)
} else {
  print("No duplicate OTUs found!")
}

# save the OTU table as a .csv file
write.csv(tele02_otu_table, "tele02_otu_table.csv")
```

## Vert01 OTU Table
```{r}
# load the marker species table from second Barque run and inspect
vert01 <- read_csv("vert01_species_table.csv")
head(vert01)
colnames(vert01)

# if TaxonName is just "MultipleHits", replace it with a concatenation of Group + Genus + Species
vert01 <- vert01 %>%
  mutate(TaxonName = ifelse(TaxonName == "MultipleHits",
                            paste(Group, Genus, Species, sep = "_"),
                            TaxonName))

# convert vert01 species table to LULU format with samples as cols and OTUs with unique ID's as rows
# select the TaxonName column and all sample columns that start with "SRR"
vert01_otu_table <- vert01 %>%
  select(TaxonName, starts_with("SRR")) # select OTU IDs + sample count columns

# rename TaxonName to OTUid (LULU expects OTU IDs in the first column) and inspect
vert01_otu_table <- vert01_otu_table %>%
  rename(OTUid = TaxonName)
head(vert01_otu_table)
dim(vert01_otu_table)

# coerce all sample columns (except OTU IDs) to numeric
vert01_otu_table <- vert01_otu_table %>%
  mutate(across(starts_with("SRR"), as.numeric)) # ensure sample counts are numeric

# move OTUid to row names (LULU expects OTU IDs as row names, not as a column)
vert01_otu_table <- vert01_otu_table %>%
  column_to_rownames(var = "OTUid")

# check if OTU IDs are unique
n_unique <- length(rownames(vert01_otu_table)) == length(unique(rownames(vert01_otu_table)))

if (n_unique) {
  print("All OTU IDs are unique!")
} else {
  print("Warning: There are duplicate OTU IDs!")
}

# check for duplicate OTUs
vert01_duplicate_otus <- vert01_otu_table %>%
  as.data.frame() %>%
  tibble::rownames_to_column(var = "OTUid") %>%  # Convert row names back to a column
  count(OTUid) %>%
  filter(n > 1)

# print duplicates
if (nrow(vert01_duplicate_otus) > 0) {
  print("Duplicates found:")
  print(vert01_duplicate_otus)
} else {
  print("No duplicate OTUs found!")
}

# save the OTU table as a .csv file
write.csv(as.data.frame(vert01_otu_table), "vert01_otu_table.csv")
```

# Generate Match Lists

Navigate to the LULU directory in the terminal. 

Commands to unzip the `marker.otus.database.fasta.gz` files:
gunzip tele02.otus.database.fasta.gz
gunzip vert01.otus.database.fasta.gz

Input files:
tele02.otus.database.fasta.gz
vert01.otus.database.fasta.gz

Commands to generate match list files for each marker using vsearch:


tele02 match list script:

vsearch --usearch_global tele02.otus.database.fasta \
        --db tele02.otus.database.fasta \
        --self --id .84 --iddef 1 \
        --userout tele02_match_list.txt \
        --userfields query+target+id \
        --maxaccepts 0 --query_cov .9 --maxhits 10
        
vert01 match list script:

vsearch --usearch_global vert01.otus.database.fasta \
        --db vert01.otus.database.fasta \
        --self --id .84 --iddef 1 \
        --userout vert01_match_list.txt \
        --userfields query+target+id \
        --maxaccepts 0 --query_cov .9 --maxhits 10

Output files:
tele02_match_list.txt
vert01_match_list.txt

## Results Summary

| Marker   | Total Sequences  | Matched Sequences | Percent Matching |
|----------|------------------|-------------------|------------------|
| Tele02   | 109              | 41                | 37.61%           |
| Vert01   | 127              | 95                | 74.80%           |


# Run LULU
Prior to running LULU, modify the fasta file headers in `tele02.otus.database.fasta` and `vert01.otus.database.fasta` using `headers_lulu.py` (Ballini et al. 2024) in the script directory.

Input files:
tele02.otus.database.fasta
vert01.otus.database.fasta

Commands to modify the fasta file headers for each marker:
python3 scripts/headers_lulu.py lulu/tele02.otus.database.fasta lulu/tele02.otus.database_lulu.fasta
python3 scripts/headers_lulu.py lulu/vert01.otus.database.fasta lulu/vert01.otus.database_lulu.fasta

Output files:
tele02.otus.database_lulu.fasta
vert01.otus.database_lulu.fasta

## Run LULU on Tele02
```{r}
# load the match list and rename columns
tele02_match_list <- read_delim("tele02_match_list.txt", 
                                delim = "\t",
                                col_names = c("query", "target", "identity"))

# check
head(tele02_match_list)
str(tele02_match_list)

# convert OTU table to a numeric matrix (LULU requires a matrix, not a tibble)
tele02_otu_table_matrix <- as.matrix(tele02_otu_table)

# run LULU with min_seq_similarity = 87
tele02_curated <- lulu(tele02_otu_table, tele02_match_list,
                       minimum_ratio_type = "min",
                       minimum_ratio = 1,
                       minimum_match = 87, # adjusted similarity ratio
                       minimum_relative_cooccurence = 0.95)

# check structure of the curated results
str(tele02_curated)

# extract curated OTU table and save as CSV (including row names)
write.csv(as.data.frame(tele02_curated$curated_table), "tele02_curated_otu_table.csv", row.names = TRUE)

# extract discarded OTUs and save as CSV (including row names)
write.csv(as.data.frame(tele02_curated$discarded_otus), "tele02_discarded_otus.csv", row.names = TRUE)

# check final structure
str(tele02_otu_table_matrix)
head(tele02_otu_table_matrix)
```

## Run LULU on Vert01
```{r}
# load the match list and rename columns
vert01_match_list <- read_delim("vert01_match_list.txt", 
                                delim = "\t",
                                col_names = c("query", "target", "identity"))

# check
head(vert01_match_list)
str(vert01_match_list)

# convert OTU table to a numeric matrix (LULU requires a matrix, not a tibble)
vert01_otu_table_matrix <- as.matrix(vert01_otu_table)

# run LULU with min_seq_similarity = 87
vert01_curated <- lulu(vert01_otu_table, vert01_match_list,
                       minimum_ratio_type = "min",
                       minimum_ratio = 1,
                       minimum_match = 87, # adjusted similarity ratio
                       minimum_relative_cooccurence = 0.95)

# check structure of the curated results
str(vert01_curated)

# extract curated OTU table and save as CSV (including row names)
write.csv(as.data.frame(vert01_curated$curated_table), "vert01_curated_otu_table.csv", row.names = TRUE)

# extract discarded OTUs and save as CSV (including row names)
write.csv(as.data.frame(vert01_curated$discarded_otus), "vert01_discarded_otus.csv", row.names = TRUE)

# check final structure
str(vert01_otu_table_matrix)
head(vert01_otu_table_matrix)
```

# Handling MultipleHits

For OTUs flagged as MultipleHits (only in the case of the vert01 marker), read counts were manually reassigned to the most abundant LULU-retained OTU with the same taxonomic assignment. This approach presumably mirrors the procedure followed by Ballini et al. (2024), as inferred from Table S3 in the Supplemental Information, where ambiguous OTUs appear to have been consolidated under the most prevalent taxonomic representative. This decision was based on a comparison between the species table output from Barque and the curated read counts presented in the supplementary material, where total read counts align with the dominant OTU among the grouped matches.

First, the `marker_curated_otu_table.csv` files were copied and renamed `marker_curated_otu_table_multihit_merge.csv` to preserve the original and create a working file for manual reassignment of MultipleHits. 

Note: only `vert01_curated_otu_table.csv` contained MultipleHits, but new working files were copied for both markers for consistency.

```{r}
# copy curated OTU tables to create working files for manual MultipleHits reassignment
file.copy("tele02_curated_otu_table.csv", 
          "tele02_curated_otu_table_multihit_merge.csv", 
          overwrite = TRUE)
file.copy("vert01_curated_otu_table.csv", 
          "vert01_curated_otu_table_multihit_merge.csv", 
          overwrite = TRUE)
```

# Aggregate OTUs
After manual assignment for MultipleHits (vert01 only), OTUs assigned to the same taxon in the resulting curated tables were merged, and their reads were aggregated across samples using `dplyr::summarise()`. 

## Aggregate Tele02
```{r}
# read the multihit merged OTU table
tele02_otu_table_merged <- read.csv("tele02_curated_otu_table_multihit_merge.csv")

# create a new Taxon column by stripping the '-otu...' suffix
tele02_otu_table_merged <- tele02_otu_table_merged %>%
  mutate(Taxon = sub("-otu.*", "", OTUid))

# group by Taxon and sum read counts across all samples
tele02_aggregated <- tele02_otu_table %>%
  group_by(Taxon) %>%
  summarise(across(where(is.numeric), sum))

# write to file
write.csv(tele02_aggregated, "tele02_curated_otu_table_aggregated.csv", row.names = FALSE)
```

## Aggregate Vert01
```{r}
# read the merged otu table
tele02_otu_table_merged <- read.csv("tele02_curated_otu_table_multihit_merge.csv")

# rename the first column to "OTUid"
colnames(tele02_otu_table_merged)[1] <- "OTUid"

# create a simplified taxonomic assignment by stripping "-otu..." from the OTUid
tele02_otu_table_merged <- tele02_otu_table_merged %>%
  mutate(Taxon = sub("-otu.*", "", OTUid))

# group by the simplified taxon and sum all read counts
tele02_aggregated <- tele02_otu_table_merged %>%
  group_by(Taxon) %>%
  summarise(across(where(is.numeric), sum), .groups = "drop")

# write the result to a new csv file
write.csv(tele02_aggregated, "tele02_curated_otu_table_aggregated.csv", row.names = FALSE)
```

As per Ballini et al. (2024), reads assigned to human and other non-target species were subsequently discarded.

```{r}
# copy curated aggregated OTU tables to create working files for manual removal of human and other non-target species and as input for microDecon
file.copy("tele02_curated_otu_table_aggregated.csv", 
          "tele02_curated_otu_table_microdecon.csv", 
          overwrite = TRUE)
file.copy("vert01_curated_otu_table_aggregated.csv", 
          "vert01_curated_otu_table_microdecon.csv", 
          overwrite = TRUE)
```

Final output files for microDecon:
tele02_curated_otu_table_microDecon.csv  
vert01_curated_otu_table_microDecon.csv


