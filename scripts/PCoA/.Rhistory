library(car)
library(ggcorrplot)
# move the files to the working directory or state the absolute path
ALUS_data <- read_csv("ALUS_reduced.csv")
pest_data <- read_csv("environment.csv")
head(ALUS_data)
head(pest_data)
# merge ALUS data with pesticide data
merged_data <- ALUS_data %>%
left_join(pest_data, by = "site_time")
setwd("~/Desktop/OneDrive - Bluewater District School Board/0_Nicole_Anthony_CBG_Internship/R_scripts_and_outputs")
head(merged_data)
# rename and remove columns
merged_data <- merged_data %>%
rename(
land_type = land_type.x,
land_IUCN = land_IUCN.x,
habitat_type = habitat_type.x) %>%
select(-land_type.y,
-habitat_type.y,
-land_IUCN.y
)
head(merged_data)
# calculate species richness for each site at each time point (year and month)
species_richness <- merged_data %>%
group_by(site_time, site_num, site_short_id, year, month, CCSUID, land_type, herb, insect, fung) %>%
summarise(species_richness = n_distinct(bin_uri), .groups = 'drop')
# check the structure of the summarized data
str(species_richness)
# merge environmental data (temp, rain, wind) back into the species richness data for later use if needed
species_richness_env <- species_richness %>%
left_join(select(merged_data, site_time, temp, rain, wind), by = "site_time") %>%
distinct()  # Ensure no duplicate rows are added
# check the structure of the merged data
str(species_richness_env)
# save to .csv
write_csv(species_richness_env, "species_richness.csv")
# aggregate data by site by calculating the mean values across all time points for each site
aggregated_data <- species_richness_env %>%
group_by(site_num, site_short_id, CCSUID, land_type, herb, insect, fung) %>%
summarise(
mean_temp = mean(temp, na.rm = TRUE),
mean_rain = mean(rain, na.rm = TRUE),
mean_wind = mean(wind, na.rm = TRUE),
mean_species_richness = mean(species_richness, na.rm = TRUE),
.groups = 'drop'
)
# rearrange columns
aggregated_data <- aggregated_data %>%
select(site_num, site_short_id, CCSUID, land_type, mean_species_richness, everything())
# check aggregated data
str(aggregated_data)
head(aggregated_data)
colnames(aggregated_data)
dim(aggregated_data)
aggregated_data
# save to .csv
write_csv(aggregated_data, "aggregated_data.csv")
# summary stats
summary(aggregated_data)
# impute missing mean_wind values with 0s
aggregated_data <- aggregated_data %>%
mutate(mean_wind = ifelse(is.na(mean_wind), 0, mean_wind))
# check
summary(aggregated_data)
# check for correlations among the predictors
# calculate correlation matrix
cor_matrix <- cor(select(aggregated_data, herb, insect, fung, mean_temp, mean_rain, mean_wind), use = "complete.obs")
# check
cor_matrix
# visualize the correlation matrix
ggcorrplot(cor_matrix, lab = TRUE)
# create a new variable for the combined pesticide input
aggregated_data <- aggregated_data %>%
mutate(total_pesticide = herb + insect + fung)
# check
str(aggregated_data)
# use `land_type`, `total_pesticide`, and the environmental covariates (mean_temp, mean_rain, mean_wind) as fixed effects, and random effect for CCSUID
# fit the lme model
model <- lmer(mean_species_richness ~ land_type + total_pesticide +
mean_temp + mean_rain + mean_wind +
(1 | CCSUID),
data = aggregated_data)
# summarize the model
summary(model)
# rescale the fixed predictors
aggregated_data_rescaled <- aggregated_data %>%
mutate(
total_pesticide_scaled = scale(total_pesticide),
mean_temp_scaled = scale(mean_temp),
mean_rain_scaled = scale(mean_rain),
mean_wind_scaled = scale(mean_wind)
)
# fit the model with the rescaled predictors
model_rescaled <- lmer(mean_species_richness ~ land_type + total_pesticide_scaled +
mean_temp_scaled + mean_rain_scaled +
mean_wind_scaled + (1 | CCSUID),
data = aggregated_data_rescaled)
# summarize the model
summary(model_rescaled)
# visualize land type vs. species richness
ggplot(aggregated_data_rescaled, aes(x = land_type, y = mean_species_richness, fill = land_type)) +
geom_boxplot() +
labs(title = "Effect of Land Type on Species Richness", x = "Land Type", y = "Mean Species Richness") +
theme_minimal()
# visualize combined pesticide input vs. species richness
ggplot(aggregated_data_rescaled, aes(x = total_pesticide_scaled, y = mean_species_richness)) +
geom_point() +
geom_smooth(method = "lm", color = "blue") +
labs(title = "Effect of Combined Pesticide Input on Species Richness",
x = "Scaled Combined Pesticide Input", y = "Mean Species Richness") +
theme_minimal()
# plot residuals vs fitted values
plot(fitted(model_rescaled), resid(model_rescaled),
xlab = "Fitted values", ylab = "Residuals",
main = "Residuals vs Fitted")
abline(h = 0, col = "red")
# Q-Q plot for residuals
qqnorm(resid(model_rescaled), main = "Normal Q-Q Plot")
qqline(resid(model_rescaled), col = "red")
# scale-Location plot
plot(fitted(model_rescaled), sqrt(abs(resid(model_rescaled))),
xlab = "Fitted values", ylab = "Square Root of |Standardized Residuals|",
main = "Scale-Location")
abline(h = 0, col = "red")
# calculate Cook's distance
cooksd <- cooks.distance(model_rescaled)
# plot Cook's distance
plot(cooksd, type="h", main="Cook's Distance", ylab="Cook's distance")
abline(h = 4/(nrow(aggregated_data_rescaled)-length(fixef(model_rescaled))), col="red") # add a reference line
vif_values <- vif(lm(mean_species_richness ~ total_pesticide_scaled + mean_temp_scaled +
mean_rain_scaled + mean_wind_scaled + land_type,
data = aggregated_data_rescaled))
print(vif_values)
# fit a GLM model
model_glm <- glm(mean_species_richness ~ land_type + total_pesticide_scaled +
mean_temp_scaled + mean_rain_scaled + mean_wind_scaled,
data = aggregated_data_rescaled, family = gaussian())
# extract coefficients and standard errors from GLM
glm_coeff <- coef(summary(model_glm))
glm_se <- glm_coeff[, "Std. Error"]
# extract coefficients and standard errors from LMM
lmm_coeff <- fixef(model_rescaled)
lmm_se <- sqrt(diag(vcov(model_rescaled)))
# combine the results into a data frame
coef_data <- data.frame(
term = names(glm_coeff[, "Estimate"]),
glm_estimate = glm_coeff[, "Estimate"],
glm_se = glm_se,
lmm_estimate = lmm_coeff,
lmm_se = lmm_se
)
# check
coef_data
# plot the coefficients
ggplot(coef_data, aes(x = term)) +
geom_point(aes(y = glm_estimate, color = "GLM"), position = position_nudge(x = -0.1)) +
geom_errorbar(aes(ymin = glm_estimate - 1.96 * glm_se, ymax = glm_estimate + 1.96 * glm_se, color = "GLM"),
width = 0.2, position = position_nudge(x = -0.1)) +
geom_point(aes(y = lmm_estimate, color = "LMM"), position = position_nudge(x = 0.1)) +
geom_errorbar(aes(ymin = lmm_estimate - 1.96 * lmm_se, ymax = lmm_estimate + 1.96 * lmm_se, color = "LMM"),
width = 0.2, position = position_nudge(x = 0.1)) +
scale_color_manual(values = c("GLM" = "black", "LMM" = "red")) +
theme_minimal() +
labs(x = "Fixed Effects", y = expression(beta), color = "Model") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
suppressWarnings({
library(dplyr)
library(readr)
library(lme4)
library(ggplot2)
library(car)
library(ggcorrplot)
})
# move the files to the working directory or state the absolute path
ALUS_data <- read_csv("ALUS_reduced.csv")
pest_data <- read_csv("environment.csv")
head(ALUS_data)
head(pest_data)
# merge ALUS data with pesticide data
merged_data <- ALUS_data %>%
left_join(pest_data, by = "site_time")
head(merged_data)
# rename and remove columns
merged_data <- merged_data %>%
rename(
land_type = land_type.x,
land_IUCN = land_IUCN.x,
habitat_type = habitat_type.x) %>%
select(-land_type.y,
-habitat_type.y,
-land_IUCN.y
)
head(merged_data)
# calculate species richness for each site at each time point (year and month)
species_richness <- merged_data %>%
group_by(site_time, site_num, site_short_id, year, month, CCSUID, land_type, herb, insect, fung) %>%
summarise(species_richness = n_distinct(bin_uri), .groups = 'drop')
# check the structure of the summarized data
str(species_richness)
# merge environmental data (temp, rain, wind) back into the species richness data for later use if needed
species_richness_env <- species_richness %>%
left_join(select(merged_data, site_time, temp, rain, wind), by = "site_time") %>%
distinct()  # Ensure no duplicate rows are added
# check the structure of the merged data
str(species_richness_env)
# save to .csv
write_csv(species_richness_env, "species_richness.csv")
# aggregate data by site by calculating the mean values across all time points for each site
aggregated_data <- species_richness_env %>%
group_by(site_num, site_short_id, CCSUID, land_type, herb, insect, fung) %>%
summarise(
mean_temp = mean(temp, na.rm = TRUE),
mean_rain = mean(rain, na.rm = TRUE),
mean_wind = mean(wind, na.rm = TRUE),
mean_species_richness = mean(species_richness, na.rm = TRUE),
.groups = 'drop'
)
# rearrange columns
aggregated_data <- aggregated_data %>%
select(site_num, site_short_id, CCSUID, land_type, mean_species_richness, everything())
# check aggregated data
str(aggregated_data)
head(aggregated_data)
colnames(aggregated_data)
dim(aggregated_data)
aggregated_data
# save to .csv
write_csv(aggregated_data, "aggregated_data.csv")
# summary stats
summary(aggregated_data)
# impute missing mean_wind values with 0s
aggregated_data <- aggregated_data %>%
mutate(mean_wind = ifelse(is.na(mean_wind), 0, mean_wind))
# check
summary(aggregated_data)
# check for correlations among the predictors
# calculate correlation matrix
cor_matrix <- cor(select(aggregated_data, herb, insect, fung, mean_temp, mean_rain, mean_wind), use = "complete.obs")
# check
cor_matrix
# visualize the correlation matrix
ggcorrplot(cor_matrix, lab = TRUE)
# create a new variable for the combined pesticide input
aggregated_data <- aggregated_data %>%
mutate(total_pesticide = herb + insect + fung)
# check
str(aggregated_data)
# use `land_type`, `total_pesticide`, and the environmental covariates (mean_temp, mean_rain, mean_wind) as fixed effects, and random effect for CCSUID
# fit the lme model
model <- lmer(mean_species_richness ~ land_type + total_pesticide +
mean_temp + mean_rain + mean_wind +
(1 | CCSUID),
data = aggregated_data)
# summarize the model
summary(model)
# rescale the fixed predictors
aggregated_data_rescaled <- aggregated_data %>%
mutate(
total_pesticide_scaled = scale(total_pesticide),
mean_temp_scaled = scale(mean_temp),
mean_rain_scaled = scale(mean_rain),
mean_wind_scaled = scale(mean_wind)
)
# fit the model with the rescaled predictors
model_rescaled <- lmer(mean_species_richness ~ land_type + total_pesticide_scaled +
mean_temp_scaled + mean_rain_scaled +
mean_wind_scaled + (1 | CCSUID),
data = aggregated_data_rescaled)
# summarize the model
summary(model_rescaled)
# visualize land type vs. species richness
ggplot(aggregated_data_rescaled, aes(x = land_type, y = mean_species_richness, fill = land_type)) +
geom_boxplot() +
labs(title = "Effect of Land Type on Species Richness", x = "Land Type", y = "Mean Species Richness") +
theme_minimal()
# visualize combined pesticide input vs. species richness
ggplot(aggregated_data_rescaled, aes(x = total_pesticide_scaled, y = mean_species_richness)) +
geom_point() +
geom_smooth(method = "lm", color = "blue") +
labs(title = "Effect of Combined Pesticide Input on Species Richness",
x = "Scaled Combined Pesticide Input", y = "Mean Species Richness") +
theme_minimal()
# plot residuals vs fitted values
plot(fitted(model_rescaled), resid(model_rescaled),
xlab = "Fitted values", ylab = "Residuals",
main = "Residuals vs Fitted")
abline(h = 0, col = "red")
# Q-Q plot for residuals
qqnorm(resid(model_rescaled), main = "Normal Q-Q Plot")
qqline(resid(model_rescaled), col = "red")
# scale-Location plot
plot(fitted(model_rescaled), sqrt(abs(resid(model_rescaled))),
xlab = "Fitted values", ylab = "Square Root of |Standardized Residuals|",
main = "Scale-Location")
abline(h = 0, col = "red")
# calculate Cook's distance
cooksd <- cooks.distance(model_rescaled)
# plot Cook's distance
plot(cooksd, type="h", main="Cook's Distance", ylab="Cook's distance")
abline(h = 4/(nrow(aggregated_data_rescaled)-length(fixef(model_rescaled))), col="red") # add a reference line
vif_values <- vif(lm(mean_species_richness ~ total_pesticide_scaled + mean_temp_scaled +
mean_rain_scaled + mean_wind_scaled + land_type,
data = aggregated_data_rescaled))
print(vif_values)
# fit a GLM model
model_glm <- glm(mean_species_richness ~ land_type + total_pesticide_scaled +
mean_temp_scaled + mean_rain_scaled + mean_wind_scaled,
data = aggregated_data_rescaled, family = gaussian())
# extract coefficients and standard errors from GLM
glm_coeff <- coef(summary(model_glm))
glm_se <- glm_coeff[, "Std. Error"]
# extract coefficients and standard errors from LMM
lmm_coeff <- fixef(model_rescaled)
lmm_se <- sqrt(diag(vcov(model_rescaled)))
# combine the results into a data frame
coef_data <- data.frame(
term = names(glm_coeff[, "Estimate"]),
glm_estimate = glm_coeff[, "Estimate"],
glm_se = glm_se,
lmm_estimate = lmm_coeff,
lmm_se = lmm_se
)
# check
coef_data
# plot the coefficients
ggplot(coef_data, aes(x = term)) +
geom_point(aes(y = glm_estimate, color = "GLM"), position = position_nudge(x = -0.1)) +
geom_errorbar(aes(ymin = glm_estimate - 1.96 * glm_se, ymax = glm_estimate + 1.96 * glm_se, color = "GLM"),
width = 0.2, position = position_nudge(x = -0.1)) +
geom_point(aes(y = lmm_estimate, color = "LMM"), position = position_nudge(x = 0.1)) +
geom_errorbar(aes(ymin = lmm_estimate - 1.96 * lmm_se, ymax = lmm_estimate + 1.96 * lmm_se, color = "LMM"),
width = 0.2, position = position_nudge(x = 0.1)) +
scale_color_manual(values = c("GLM" = "black", "LMM" = "red")) +
theme_minimal() +
labs(x = "Fixed Effects", y = expression(beta), color = "Model") +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
pcoa_plot_data <- left_join(pcoa_scores, metadata, by = "SampleID")
# load libraries
library(vegan)    # for Bray-Curtis dissimilarity, PCoA and PERMANOVA
library(ape)      # for PCoA function
library(ggplot2)  # for plotting
library(dplyr)    # for data wrangling
library(tidyr)    # for reshaping data
library(readr)    # for reading CSV files
library(devtools)
# install_github("pmartinezarbizu/pairwiseAdonis/pairwiseAdonis")
library(pairwiseAdonis) # for pairwise PERMANOVA (Post-Hoc)
setwd("~/Desktop/eDNA_projects/Italy/analyses/PCoA")
# set working directory
setwd("/Users/Angel/Desktop/eDNA_projects/Italy/analyses/PCoA")
# list all relevant csv files
otu_files <- list.files(pattern = "*_cleaned.csv")  # ignore microdecon input files
# function to read and process each OTU table
load_otu_data <- function(file) {
df <- read_csv(file)
# extract river and marker from filename (assuming "marker_river_cleaned.csv" format)
file_parts <- strsplit(file, "_")[[1]]
marker <- file_parts[1]  # tele02 or vert01
river <- file_parts[2]   # argentina, bevera, etc.
# reshape from wide to long format: OTU_ID, SampleID, Read_Count
df_long <- pivot_longer(df, cols = -OTU_ID, names_to = "SampleID", values_to = "Read_Count")
# add metadata columns
df_long$River <- river
df_long$Marker <- marker
return(df_long)
}
# load and merge all OTU tables
otu_data <- bind_rows(lapply(otu_files, load_otu_data))
otu_data <- otu_data %>%
mutate(Presence = ifelse(Read_Count > 0, 1, 0)) %>%  # convert to binary
select(-Read_Count)  # remove raw read counts
# reshape back to wide format: Samples as rows, OTUs as columns
otu_wide <- otu_data %>%
pivot_wider(names_from = "OTU_ID", values_from = "Presence", values_fill = 0)
# extract metadata
metadata <- otu_wide %>% select(SampleID, River, Marker)
# remove non-numeric columns to create the OTU presence-absence matrix
otu_matrix <- otu_wide %>% select(-SampleID, -River, -Marker)
# identify Samples with No OTUs
# count the number of OTUs per sample
otu_nonzero_counts <- rowSums(otu_matrix)
# identify samples with zero OTUs
empty_samples <- metadata$SampleID[otu_nonzero_counts == 0]
# print empty samples
print(empty_samples)
# filter out samples with no detected OTUs
otu_matrix_filtered <- otu_matrix[rowSums(otu_matrix) > 0, ]
metadata_filtered <- metadata[rowSums(otu_matrix) > 0, ]
dist_matrix <- vegdist(otu_matrix_filtered, method = "bray")
# check if missing values persist
any(is.na(dist_matrix))
pcoa_result <- pcoa(dist_matrix)
# extract first two principal coordinates
pcoa_scores <- as.data.frame(pcoa_result$vectors[, 1:2])
colnames(pcoa_scores) <- c("PCoA1", "PCoA2")
pcoa_scores$SampleID <- metadata_filtered$SampleID
pcoa_plot_data <- left_join(pcoa_scores, metadata, by = "SampleID")
ggplot(pcoa_plot_data, aes(x = PCoA1, y = PCoA2, color = River, shape = Marker)) +
geom_point(size = 4, alpha = 0.8) +
stat_ellipse(aes(group = interaction(River, Marker)), linetype = "dashed") +  # fixes warning
theme_minimal() +
labs(title = "PCoA of eDNA Samples by River and Primer Marker (Bray-Curtis, Presence/Absence)",
x = paste0("PCoA1 (", round(pcoa_result$values$Relative_eig[1] * 100, 2), "%)"),
y = paste0("PCoA2 (", round(pcoa_result$values$Relative_eig[2] * 100, 2), "%)"),
color = "River",
shape = "Marker")
# Run PERMANOVA using Bray-Curtis distance matrix
permanova_result <- adonis2(dist_matrix ~ River * Marker, data = metadata_filtered, permutations = 999, method = "bray")
# Print results
print(permanova_result)
# Pairwise comparisons for River
pairwise_result <- pairwise.adonis2(dist_matrix ~ River, data = metadata_filtered, permutations = 999)
# Print results
print(pairwise_result)
pcoa_plot_data <- left_join(pcoa_scores, metadata, by = "SampleID")
ggplot(pcoa_plot_data, aes(x = PCoA1, y = PCoA2, color = River, shape = Marker)) +
geom_point(size = 4, alpha = 0.8) +
stat_ellipse(aes(group = interaction(River, Marker)), linetype = "dashed") +  # fixes warning
theme_minimal() +
labs(title = "PCoA of eDNA Samples by River and Primer Marker
(Bray-Curtis, Presence/Absence)",
x = paste0("PCoA1 (", round(pcoa_result$values$Relative_eig[1] * 100, 2), "%)"),
y = paste0("PCoA2 (", round(pcoa_result$values$Relative_eig[2] * 100, 2), "%)"),
color = "River",
shape = "Marker")
# for tele02 only
tele_data <- metadata_filtered %>% filter(Marker == "tele02")
tele_dist <- vegdist(otu_matrix_filtered[metadata_filtered$Marker == "tele02", ], method = "bray")
adonis2(tele_dist ~ River, data = tele_data, permutations = 999)
# for vert01 only
vert_data <- metadata_filtered %>% filter(Marker == "vert01")
vert_dist <- vegdist(otu_matrix_filtered[metadata_filtered$Marker == "vert01", ], method = "bray")
adonis2(vert_dist ~ River, data = vert_data, permutations = 999)
ggplot(pcoa_plot_data, aes(x = PCoA1, y = PCoA2, color = River)) +
geom_point(size = 4, alpha = 0.8) +
stat_ellipse(aes(group = River), linetype = "dashed") +
facet_wrap(~ Marker) +
theme_minimal() +
labs(title = "PCoA of eDNA Samples by River, Faceted by Primer Marker",
x = paste0("PCoA1 (", round(pcoa_result$values$Relative_eig[1] * 100, 2), "%)"),
y = paste0("PCoA2 (", round(pcoa_result$values$Relative_eig[2] * 100, 2), "%)"),
color = "River")
# calculate Bray-Curtis distance matrix (already done, but just in case)
dist_matrix <- vegdist(otu_matrix_filtered, method = "bray")
# run PERMDISP: test if dispersion differs between tele02 and vert01
group_dispersion <- betadisper(dist_matrix, metadata_filtered$Marker)
# test for significance
permdisp_result <- permutest(group_dispersion, permutations = 999)
print(permdisp_result)
# optionally plot
plot(group_dispersion)
print(permdisp_result)
# optionally plot
plot(group_dispersion)
print(permdisp_result)
plot(group_dispersion)
print(permdisp_result)
library(vegan)        # Bray-Curtis, PERMANOVA, PERMDISP
library(ape)          # PCoA function
library(ggplot2)      # plotting
library(dplyr)        # data wrangling
library(tidyr)        # reshaping
library(readr)        # reading csv
library(pairwiseAdonis) # pairwise PERMANOVA
setwd("/Users/Angel/Desktop/eDNA_projects/Italy/analyses/PCoA")
otu_files <- list.files(pattern = "*_cleaned.csv")
load_otu_data <- function(file) {
df <- read_csv(file)
file_parts <- strsplit(file, "_")[[1]]
marker <- file_parts[1]
river <- file_parts[2]
df_long <- df %>%
pivot_longer(cols = -OTU_ID, names_to = "SampleID", values_to = "Read_Count") %>%
mutate(River = river, Marker = marker)
return(df_long)
}
otu_data <- bind_rows(lapply(otu_files, load_otu_data))
otu_data <- otu_data %>%
mutate(Presence = ifelse(Read_Count > 0, 1, 0)) %>%
select(-Read_Count)
otu_wide <- otu_data %>%
pivot_wider(names_from = OTU_ID, values_from = Presence, values_fill = 0)
metadata <- otu_wide %>% select(SampleID, River, Marker)
otu_matrix <- otu_wide %>% select(-SampleID, -River, -Marker)
nonzero_samples <- rowSums(otu_matrix) > 0
otu_matrix_filtered <- otu_matrix[nonzero_samples, ]
metadata_filtered <- metadata[nonzero_samples, ]
dist_matrix <- vegdist(otu_matrix_filtered, method = "bray")
pcoa_result <- pcoa(dist_matrix)
pcoa_scores <- as.data.frame(pcoa_result$vectors[, 1:2])
colnames(pcoa_scores) <- c("PCoA1", "PCoA2")
pcoa_scores$SampleID <- metadata_filtered$SampleID
pcoa_plot_data <- left_join(pcoa_scores, metadata_filtered, by = "SampleID")
ggplot(pcoa_plot_data, aes(x = PCoA1, y = PCoA2, color = River)) +
geom_point(size = 4, alpha = 0.8) +
stat_ellipse(aes(group = River), linetype = "dashed") +
facet_wrap(~ Marker) +
theme_minimal() +
labs(title = "PCoA of eDNA Samples by River, Faceted by Primer Marker",
x = paste0("PCoA1 (", round(pcoa_result$values$Relative_eig[1]*100, 2), "%)",
y = paste0("PCoA2 (", round(pcoa_result$values$Relative_eig[2]*100, 2), "%))")
permanova_result <- adonis2(dist_matrix ~ River * Marker, data = metadata_filtered, permutations = 999)
permanova_result
pairwise_result <- pairwise.adonis2(dist_matrix ~ River, data = metadata_filtered, permutations = 999)
pairwise_result
tele_data <- metadata_filtered %>% filter(Marker == "tele02")
tele_dist <- vegdist(otu_matrix_filtered[metadata_filtered$Marker == "tele02", ])
adonis2(tele_dist ~ River, data = tele_data)
vert_data <- metadata_filtered %>% filter(Marker == "vert01")
vert_dist <- vegdist(otu_matrix_filtered[metadata_filtered$Marker == "vert01", ])
adonis2(vert_dist ~ River, data = vert_data)
